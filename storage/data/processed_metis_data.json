[
  {
    "text": "Getting Started  to Run a command , One of the very first things you may want to do with metis-cli , is creating a new connection to your database. \n\nmetis-cli add-connection \"connection-name\" \"postgres\" \\\n\"postgresql://user:password@1.2.3.4:5432/database-name\" \\\n\"connection-description\" ; to Update the CLI - brew tap metis-data/cli-brew && brew reinstall metis-cli . permanent Installation & brew update && brew tap metis-data/cli-brew && brew reinstall metis-cli\n\nElse, you can download the CLI from GitHub. \n\nThe CLI works only with MacOS and Linux\n\nVerify the installation had finished successfully using  metis-cli --version . they Work in the interactive (REPL) Mode . To work in the interactive mode simply run the command metis-cli . The terminal will show you the current version and wait for your next command. \n\nNow you can run the command as a function, parameters are separated by commas. \n\naddConnection(\"connection-name\", \"postgres\", \"postgresql://user:password@1.2.3.4:5432/database-name\",  \"connection-description\") ."
  },
  {
    "text": "Python - SQLAlchemy  , we get you up and running with Metis' SDK for Python, so that it will automatically send the SQL commands, with their caller REST / GraphQL, from the application. Metis SDK supports Python  SQLAlchemy with FastAPI and or Flask. \nSupporting Django is coming soon.\n\nIf you don't have an API Key yet, sign up to Metis at http://metisdata.io to get one. It can be found under the API Key page.  step 1. Install . Install our Python SDK using pip . the Source Code of The Source code of the Python SDK and a demo app can be found on our GitHub.  . type 2. Send Data . Now you can run your application as you normally would, and interact with it in a manner that causes the server to interact with your database. . the FastAPI (Sync) and pip install fastapialchemycollector . - FastAPI (Async) - pip install fastapialchemycollector . n Sync : DATABASE_URI=postgresql://postgres:postgres@postgres:5432/fastapi ; SQLAlchemy + Flask\nfrom flask import Flask\nfrom flask_sqlalchemy import SQLAlchemy\nfrom sqlalchemycollector import setup, MetisInstrumentor, PlanCollectType\n# existing app initialization\napp = Flask(...)\ndb = SQLAlchemy(app)\n# The default log file name is 'metis-log-collector.log. You can change the default name. \noptional_log_file_name = 'new_file_name_of_sqlalchemy_logs.log'\n# By default, the package logs the SQL commands and their execution plan. \n# It can also be configured manually to collect only the SQL commands using PlanCollectType.NONE. \n# We recommend collecting the estimated plan too.\noptional_plan_collect_type = PlanCollectType.NONE\n# class PlanCollectType(Enum):\n#     NONE = 0\n#     ESTIMATED = 1\n# To start collecting the logs:\ninstrumentation: MetisInstrumentor = setup('service-name',\n                                           service_version='1.0.0',\n                                           plan_collection_option=PlanCollectType.ESTIMATED,\n                                           dsn=\"<URL>\",\n                                           api_key='<API_KEY>')\ninstrumentation.instrument_app(app, db.get_engine()) a Flask import from flask import Flask\nfrom flask_sqlalchemy import SQLAlchemy\nfrom sqlalchemycollector import setup, MetisInstrumentor, PlanCollectType\napp = Flask(__name__)\ndb = SQLAlchemy(app)\nwith app.app_context():\n    instrumentation: MetisInstrumentor = setup(\n        service_name='<SERVICE_NAME>',\n        api_key='<API_KEY>',\n        service_version='<SERVICE_VERSION>'\n    )\n    instrumentation.instrument_app(app, db.get_engine())\n@app.route(\"/hello\")\ndef home():\n    return \"Hello, Flask!\" ; Metis SDK supports Python SQLAlchemy ORM with FastAPI or Flask.\n\nYou will need your project token for initializing your library. You can get your project token from Projects Page. \u00a7 2. Configure and Open your app's main.py and add the following code- . step 3. Check for Success ! Open Up Metis Recent Activity to view your insights! ! - FastAPI (Async) engine from fastapi import FastAPI, APIRouter\nfrom sqlalchemy.ext.asyncio import create_async_engine\nfrom fastapialchemycollector import setup, MetisInstrumentor, PlanCollectType\napp = FastAPI()\napi_router = APIRouter()\napp.include_router(api_router)\nDATABASE_URL = \"postgresql+asyncpg://user_name:user_password@host_name:port/db_name\"\nasync_engine = create_async_engine(DATABASE_URL, echo=True)\ninstrumentation: MetisInstrumentor = setup(\n    service_name='<SERVICE_NAME>',\n    api_key='<API_KEY>',\n    service_version='<SERVICE_VERSION>',\n)\ninstrumentation.instrument_app(app, async_engine) ; a Flask install pip install sqlalchemycollector . other Environment Variables : METIS_INSTRUMENTATION\nSet false to stop all data collection, any other value activates Metis. ; step 3. Check for Success ! Open Up Metis Recent Activity to view your insights! ! and SQLAlchemy + Fast API . import os\nfrom sqlalchemy import create_engine\nfrom fastapi import FastAPI\nfrom fastapialchemycollector import setup, MetisInstrumentor, PlanCollectType\n# existing app initialization\napp = FastAPI()\nengine = create_engine(os.environ['DATABASE_URI'])\n# To start collecting the logs:\ninstrumentation: MetisInstrumentor = setup('<SERVICE_NAME>',\n                                           service_version='<SERVICE_VERSION>',\n                                           plan_collection_option=PlanCollectType.ESTIMATED,\n                                           dsn=\"<URL>\",\n                                           api_key='<API_KEY>')\ninstrumentation.instrument_app(app, engine)\n\nThe property DATABASE_URI can be used in sync or a-sync mode. \n\nAsync: DATABASE_URI=postgresql+asyncpg://postgres:postgres@postgres:5432/fastap \nSync:\nDATABASE_URI=postgresql://postgres:postgres@postgres:5432/fastapi ; other Environment Variables : METIS_API_KEY\n<String> API Key to use\nMETIS_ENVIRONMENT\n<String> Text used to identify the source that sends the instrumentation data.\nWe suggest you Read This Page to fully understand this feature\nMETIS_DISABLED\n<Boolean> If True Metis Instrumentation is fully disabled. We strongly advise to disable the instrumentation when in production to prevent sensitive data from leaving your organization's database.\nMETIS_SERVICE_NAME\n<String> Gives ability to distinguish between services. Useful when working with Micro Services. . type 2. Send Data . Now you can run your application as you normally would, and interact with it in a manner that causes the server to interact with your database. . system Configuration Parameters - SERVICE_NAME\nA short name to easily group data coming from the service.\norders-service\nSERVICE_VERSION\nOptional. An internal version of the service, to help the developers to distinguish between data from different versions.\n1.2.3\nAPI_KEY\nYour project's API key.\nz9bayHMU69amS9KmdjnTo1bqVqoX1Fa11IlRp2Aq . abbreviated Async : DATABASE_URI=postgresql+asyncpg://postgres:postgres@postgres:5432/fastap  ; the FastAPI (Sync) engine from fastapi import FastAPI, APIRouter\nfrom fastapialchemycollector import setup, MetisInstrumentor, PlanCollectType\nfrom database.connection import engine\napp = FastAPI()\napi_router = APIRouter()\napp.include_router(api_router)\nDATABASE_URL = \"postgresql://user_name:user_password@host_name:port/db_name\"\nengine = create_engine(DATABASE_URL)\ninstrumentation: MetisInstrumentor = setup(\n    service_name='<SERVICE_NAME>',\n    api_key='<API_KEY>',\n    service_version='<SERVICE_VERSION>'\n)\ninstrumentation.instrument_app(app, engine)\n@api_router.get(\"/hello\", status_code=200)\ndef helloWorld():\n    return \"Hello World!\" ;"
  },
  {
    "text": "Query Analyzer  Quickly analyze a query, without any instrumentation. 2. Retrieve the Execution Plan\nTo get the execution plan of the SQL Code add the following code to it-\n\nEXPLAIN (ANALYZE, COSTS, VERBOSE, BUFFERS, TIMING, FORMAT JSON)\nselect *\nfrom postgres_air.flight\nwhere flight_id = 108340\n\nThe execution plan must be created using either \nActual - EXPLAIN (ANALYZE, COSTS, VERBOSE, BUFFERS, TIMING, FORMAT JSON)\nEstimated - EXPLAIN (COSTS, VERBOSE, BUFFERS, FORMAT JSON)\n\nRunning this code generates the following JSON string-\n\n{\n  \"Plan\": {\n    \"Node Type\": \"Index Scan\",\n    \"Parallel Aware\": false,\n    \"Scan Direction\": \"Forward\",\n    \"Index Name\": \"flight_pkey\",\n    \"Relation Name\": \"flight\",\n    \"Schema\": \"postgres_air\",\n    \"Alias\": \"flight\",\n    \"Startup Cost\": 0.42,\n    \"Total Cost\": 8.44,\n    \"Plan Rows\": 1,\n    \"Plan Width\": 71,\n    \"Output\": [\n      \"flight_id\",\n      \"flight_no\",\n      \"scheduled_departure\",\n      \"scheduled_arrival\",\n      \"departure_airport\",\n      \"arrival_airport\",\n      \"status\",\n      \"aircraft_code\",\n      \"actual_departure\",\n      \"actual_arrival\",\n      \"update_ts\"\n    ],\n    \"Index Cond\": \"(flight.flight_id = 108340)\",\n    \"Shared Hit Blocks\": 0,\n    \"Shared Read Blocks\": 0,\n    \"Shared Dirtied Blocks\": 0,\n    \"Shared Written Blocks\": 0,\n    \"Local Hit Blocks\": 0,\n    \"Local Read Blocks\": 0,\n    \"Local Dirtied Blocks\": 0,\n    \"Local Written Blocks\": 0,\n    \"Temp Read Blocks\": 0,\n    \"Temp Written Blocks\": 0,\n    \"I/O Read Time\": 0,\n    \"I/O Write Time\": 0\n  },\n  \"Planning\": {\n    \"Shared Hit Blocks\": 0,\n    \"Shared Read Blocks\": 0,\n    \"Shared Dirtied Blocks\": 0,\n    \"Shared Written Blocks\": 0,\n    \"Local Hit Blocks\": 0,\n    \"Local Read Blocks\": 0,\n    \"Local Dirtied Blocks\": 0,\n    \"Local Written Blocks\": 0,\n    \"Temp Read Blocks\": 0,\n    \"Temp Written Blocks\": 0,\n    \"I/O Read Time\": 0,\n    \"I/O Write Time\": 0\n  },\n  \"Planning Time\": 0.066\n} version 3. Run Query Analyzer , Go to Query Analyzer, paste and submit the sql code and execution plan accordingly.\n\nQuery Analyzer Page\n\nFurther Details\nRead the Official PostgreSQL documentation about Execution Plans. . to Learn by Example .  . note 1. Note the SQL Command : select *\nfrom postgres_air.flight\nwhere flight_id = 108340 ."
  },
  {
    "text": "View in Web App  The CLI has limited UI, viewing Query Analysis in our Web App provides a much better UX, richer insights and tools to understand them and fix them.  # 2. Run .  . no 3. Open source Web App view of Query Analysis results . \u00a7 1. Configure , Open your projects page and copy your API Key.\n\nProjects Page\n\nEnter API Key . - CLI - metis-cli set-api-key '<API_KEY>' . & REPL . setApiKey('<API_KEY>') ; - CLI - metis-cli query-analysis \"select count (*) from sales.order_lines where quantity > 315\" . \" You're all Set!  \"  . see How it Works . Configure the CLI with an API Key.\nNow, whenever you run query-analysis from the CLI, you will be provided with a link to view the results on our web app.\nOpen the link  . & REPL . queryAnalysis(\"select count (*) from sales.order_lines where quantity > 315\") ;"
  },
  {
    "text": "Advanced  step 3. Check for Success ! Open Up Metis Recent Activity to view your insights! ! 1. Install\nRun the following command to install the SDK using npm-\n\nnpm install --save @metis-data/prisma-interceptor\n\nOpen your prisma.schema and add to your generator client struct the following line-\n\ngenerator client {\n  ...\n  previewFeatures = [\"tracing\"] // Add this line.\n}\n\nRun the following command-\n\nprisma generate\n\nIf you followed the NestJS docs to implement Prisma, you already created a prisma.service.ts. Open it and add the following code-\n\nimport { setInstrumentedPrismaClient } from \"@metis-data/prisma-interceptor\";\nimport { Injectable, OnModuleInit } from \"@nestjs/common\";\nimport { PrismaClient } from \"@prisma/client\";\n@Injectable()\nexport class PrismaService extends PrismaClient implements OnModuleInit {\n    constructor() {\n        super({\n            log: [{\n                emit: \"event\",\n                level: \"query\",\n            }]\n        });\n    }\n    async onModuleInit() {\n        await this.$connect();\n        setInstrumentedPrismaClient(this)\n    }\n}\n\nOpen your main.ts and add the following code-\n\nimport { NestFactory } from '@nestjs/core';\nimport { AppModule } from './app.module';\nimport { StartMetisInstrumentation } from './tracer' \nStartMetisInstrumentation()\nasync function bootstrap() {\n  const app = await NestFactory.create(AppModule);\n  await app.listen(3001);\n}\nbootstrap();\n\nCreate tracer.ts with the following code-\n\nimport opentelemetry from '@opentelemetry/api';\nimport { HttpInstrumentation } from '@opentelemetry/instrumentation-http';\nimport { registerInstrumentations } from '@opentelemetry/instrumentation';\nimport { Resource } from '@opentelemetry/resources';\nimport {\n  BasicTracerProvider,\n  BatchSpanProcessor,\n  ConsoleSpanExporter,\n  SimpleSpanProcessor,\n} from '@opentelemetry/sdk-trace-base';\nimport { SemanticResourceAttributes } from '@opentelemetry/semantic-conventions';\nimport { AsyncHooksContextManager } from '@opentelemetry/context-async-hooks';\nimport {\n  createFilter,\n  getPrismaInstrumentation,\n  markSpan,\n  getMetisExporter,\n} from '@metis-data/prisma-interceptor';\nimport { IncomingMessage } from 'http';\n// @ts-ignore\nBigInt.prototype.toJSON = function () {\n    return this.toString();\n};\nexport const StartMetisInstrumentation = (\n  apiKey: string = process.env.METIS_API_KEY,\n  serviceName: string = process.env.METIS_SERVICE_NAME,\n  serviceVersion: string = process.env.npm_package_version,\n  environmentName: string = process.env.METIS_ENVIRONMENT,\n  enabled: string = !process.env.METIS_DISABLED) => {\n  const tracerProvider = new BasicTracerProvider({\n    resource: new Resource({\n      [SemanticResourceAttributes.SERVICE_NAME]: serviceName,\n      [SemanticResourceAttributes.SERVICE_VERSION]: serviceVersion,\n    }),\n  });\n  const metisExporter = getMetisExporter(apiKey, environmentName, enabled);\n  tracerProvider.addSpanProcessor(new BatchSpanProcessor(metisExporter));\n  const contextManager = new AsyncHooksContextManager().enable();\n  opentelemetry.context.setGlobalContextManager(contextManager);\n  tracerProvider.register();\n  const urlsFilter = createFilter([/favicon.ico/]);\n  registerInstrumentations({\n    instrumentations: [\n      new HttpInstrumentation({\n        ignoreOutgoingRequestHook: () => true,\n        ignoreIncomingRequestHook: (request: IncomingMessage) => {\n          return urlsFilter(request.url);\n        },\n        requestHook: markSpan,\n      }),\n      getPrismaInstrumentation(),\n    ],\n  });\n}; other Environment Variables : METIS_API_KEY\n<String> API Key to use\nMETIS_ENVIRONMENT\n<String> Text used to identify the source that sends the instrumentation data.\nWe suggest you Read This Page to fully understand this feature\nMETIS_DISABLED\n<Boolean> If True Metis Instrumentation is fully disabled. We strongly advise to disable the instrumentation when in production to prevent sensitive data from leaving your organization's database.\nMETIS_SERVICE_NAME\n<String> Gives ability to distinguish between services. Useful when working with Micro Services. . type 2. Send Data . Now you can run your application as you normally would, and interact with it in a manner that causes the server to interact with your database. ."
  },
  {
    "text": "Get an API Key  special Projects Page . Your API Key is located in the Project Page on each Project's card.\n\nProjects Page . API Keys are required by the SDK and the Production Metadata Collector to send data for analysis."
  },
  {
    "text": "General  information About the Production Metadata Collector : The Production Metadata Collector (PMC) collects metadata to improve the quality of the insights by analyzing not just the Dev environment but also the Production one. \nSince the collector was designed for the Production env, it was built using the following principles: \n\nData Security - The collector only pushes data out and never listens to external requests\nData Privacy - the collector only collects metadata, such as table sizes and indexes usage. \nPerformance - super efficient SQL queries which work on the system catalog and finish in less than 1 second. The queries run every 6-24 hours. \nPerformance - collects only the necessary data for insights. An SQL query is added only if it is used by an insight. \nTransparency - The code is open-sourced, MIT license.  ; digital Data Security : The collector only pushes data out and never listens to external requests. . digital Data Privacy : The collector collects metadata, such as tables structure, tables size, indexes structure, schema and functions. . public Transparency of  The code is Open Source (MIT license). . group Performance : Super efficient SQL queries which work on the system catalog and finish in less than 1 second. The queries run every 4-24 hours. . the Web App - Reports on The collected data and insights on that data can be found under the page \"Reports\" in the web app . the View Collected Metadata . Note the PMC on the right side\n\nMetadata from PMC . see How it Works . The Production Metadata Collector (PMC) collects metadata from your production database. It then uses the metadata to predict how queries from Local and Staging environments would perform on your real production database, without actually running them on it.\n\n\nSince the collector was designed for the Production env, it was built using the following principles: . Since our SDK collects actual query data, we advise our users to not install it in Production Environment, as it will expose Metis to users' data, and might slow down performance."
  },
  {
    "text": "NestJS  step 3. Check for Success ! Open Up Metis Recent Activity to view your insights! ! 1. Install\nUse the following to install into a project using NPM.\n\nnpm install --save @metis-data/prisma-nest-interceptor\n\nWhen using @prisma/client above 4.6.1 running the following command is sometimes needed -\nnpm install --save @metis-data/prisma-nest-interceptor --legacy-peer-d\neps\n\nOpen your prisma.schema and add to your generator client struct the following line-\n\ngenerator client {\n  ...\n  previewFeatures = [\"tracing\"] // Add this line.\n}\n\nCreate prismaService and make sure it has the following code-\n\nimport { setPrismaClient } from \"@metis-data/prisma-nest-interceptor\";\nimport { Injectable, OnModuleInit } from \"@nestjs/common\";\nimport { PrismaClient } from \"@prisma/client\";\n@Injectable()\nexport class PrismaService extends PrismaClient implements OnModuleInit {\n    constructor() {\n        super({\n            log: [{\n                emit: \"event\",\n                level: \"query\",\n            }]\n        });\n    }\n    async onModuleInit() {\n        await this.$connect();\n        setPrismaClient(this)\n    }\n}\n\nOpen your main.ts and add the following code-\n\nimport { NestFactory } from '@nestjs/core';\nimport { AppModule } from './app.module';\nimport { PrismaNestInterceptor } from '@metis-data/prisma-nest-interceptor';\n// @ts-ignore\nBigInt.prototype.toJSON = function () {\n  return this.toString();\n};\nconst interceptor = PrismaNestInterceptor.create({\n  serviceName: <SERVICE_NAME>,\n  serviceVersion: <SERVICE_VERSION>,\n  exporterApiKey: <YOUR_API_KEY>\n});\ninterceptor.instrument();\nasync function bootstrap() {\n  const app = await NestFactory.create(AppModule);\n  await app.listen(3001);\n}\nbootstrap(); Metis SDK supports Prisma ORM, Node.js and NestJS.\n\nYou will need your project token for initializing your library. You can get your project token from Projects Page. you Already have OpenTelemetry in your app? !  ! type 2. Send Data . Now you can run your application as you normally would, and interact with it in a manner that causes the server to interact with your database. . post Production _ METIS_TAG=PRODUCTION . someone New to OpenTelemetry? '  ."
  },
  {
    "text": "FAQ "
  },
  {
    "text": "Built-in Help  View All Supported Commands.\n\nmetis-cli help\n\nView detailed help of a specific command.\n\nmetis-cli doc <command-name> - Auto Complete - Some of the commands has built-in auto complete. When you start typing, the CLI suggest parameter's values or relevant objects. You can also click twice on TAB to see all relevant options. \n\nExample - The command connect() expects an existing connection name to a database. The auto completion suggests a connection name from the list of existing connections. Tapping TAB twice will show all possible connections.\n\nAuto Complete . please View Detailed Command's Documentation . To learn more about a specific command run doc(command-name). For ex. The command queryAnalysis() is quite complicated, and expect a few parameters. Run doc(\"queryAnalysis\") to learn how to use it (or continue reading the documentation). \n\ndoc(\"queryAnalysis\") ."
  },
  {
    "text": "Simple  step 3. Check for Success ! Open Up Metis Recent Activity to view your insights! ! 1. Install\nRun the following command to install the SDK using npm-\n\nnpm install --save @metis-data/prisma-express-interceptor\n\nOpen your prisma.schema and add to your generator client struct the following line-\n\ngenerator client {\n  ...\n  previewFeatures = [\"tracing\"] // Add this line.\n}\n\nRun the following command-\n\nprisma generate\n\nOpen your main.ts and add the following code-\n\nimport { PrismaClient } from \"@prisma/client\";\nimport { PrismaExpressInterceptor } from '@metis-data/prisma-express-interceptor';\nconst prisma = new PrismaClient({\n  log: [\n    {\n      emit: 'event',\n      level: 'query'\n    }\n  ]\n});\nconst interceptor = PrismaExpressInterceptor.create({\n  serviceName: '<SERVICE_NAME>',\n  serviceVersion: '<SERVICE_VERSION>',\n  apiKey: '<API_KEY>'\n});\ninterceptor.instrument(prisma, {\n    // Add URL Regex to exclude instrumentation from.\n    excludedUrls: [/favicon.ico/],\n});\n// Import Express after the instrumentation.\nimport express from \"express\";\nconst app = express();\nconst port = 8000;\napp.listen(port, () => {\n  console.log(`Server is listening on port ${port}`);\n}); type 2. Send Data . Now you can run your application as you normally would, and interact with it in a manner that causes the server to interact with your database. . other Environment Variables : METIS_API_KEY\n<String> API Key to use\nMETIS_ENVIRONMENT\n<String> Text used to identify the source that sends the instrumentation data.\nWe suggest you Read This Page to fully understand this feature\nMETIS_DISABLED\n<Boolean> If True Metis Instrumentation is fully disabled. We strongly advise to disable the instrumentation when in production to prevent sensitive data from leaving your organization's database.\nMETIS_SERVICE_NAME\n<String> Gives ability to distinguish between services. Useful when working with Micro Services. ."
  },
  {
    "text": "Production  Since our SDK collects actual query data, we advise our users to not install it in Production Environment, as it will expose Metis to users' data, and might slow down performance.\n\nInstead we offer a Production Metadata Collector (PMC) that collects only metadata from the production database. The metadata gathered by it is then used to enrich insights in earlier stages of the software development life cycle. the View Collected Metadata . Note the PMC on the right side\n\nMetadata from PMC . he Set Up a PMC .  '"
  },
  {
    "text": "Metis Building Blocks  not A Trace . Traces give us the big picture of what happens when a request is made by user or an application. A Trace in Metis contains: \n\nA REST / GraphQL command - Routh, method, status, duration...\nThe SQL Command(s) generated by the REST / GQL. \nThe estimated execution plan of each SQL Command. \n\nMetis uses the Open Telemetry specification to define the Traces. The goal of Open Telemetry is to provide a set of standardized vendor-agnostic SDKs, APIs, and tools for ingesting, transforming, and sending data to an Observability back-end (i.e. open-source or commercial vendor). . develop An Execution Plan  . an execution plan  is the various steps that are involved in fetching results from the database tables. Once a query is executed, the Query Optimizer of the DB Engine quickly generates multiple execution plans and selects the one which returns the results with the best performance. \n\nThere are two types of execution plans\n\nEstimated Execution Plan \u2013 As the name suggests, this type of execution plan is just a guess by the query processor about how the specific steps that are to be involved while returning the results. It is  generated BEFORE the query has been executed and usually generated very quickly. \nActual Execution Plan \u2013 The Actual Execution Plan is generated AFTER the query has been executed. It shows the actual operations and steps involved while executing the query. This may or may not differ from the Estimated Execution Plan. Since this is the actual execution of the SQL Command, it might take a long time for the command to finish. Furthermore, the INSERT / UPDATE and DELETE commands actually modify the data in the tables when the actual plan is executed.  . no Trace . Traces give us the big picture of what happens when a request is made by user or an application. A Trace in Metis contains: \n\nA REST / GraphQL command - Routh, method, status, duration...\nThe SQL Command(s) generated by the REST / GQL. \nThe estimated execution plan of each SQL Command. \n\nMetis uses the Open Telemetry specification to define the Traces. The goal of Open Telemetry is to provide a set of standardized vendor-agnostic SDKs, APIs, and tools for ingesting, transforming, and sending data to an Observability back-end (i.e. open-source or commercial vendor). . half A Span  . A Span represents a unit of work or operation. Spans are the building blocks of Traces. In OpenTelemetry, they include the following information:\n\nName\nStart and End Timestamps\nSpan Context\nAttributes\nSpan Events\nSpan Links\nSpan Status . for An Insight , An Insight is the interpretation of Metrics. An insight evaluates the status and generates clear problems the user should be aware of, with a reasonable and explainable severity. \n\nAn Insight contains \n\nQuick summary of the problem\nAutomated Investigation - detailed analysis of the thought process, what Metrics were calculated, and how the severity of the problem was evaluated. \nThe Impact of ignoring the problem. \nA Remediation Plan to solve the problem. \nReferences to a Knowledge Base for more information about the problem and how to fix it.   . is A Metric . A Metric describes and measures quantitatively elements of a database. The Metrics are seen as facts, not good, not bad. \n\nFor ex. \n\nThe duration of a query\nNumber of rows in a table\nLast update of the statistics in a table\nDB size\nThe cost of a specific operation in a specific query    . the Metric ##s A Metric describes and measures quantitatively elements of a database. The Metrics are seen as facts, not good, not bad. \n\nExamples:\n\nThe duration of a query\nNumber of rows in a table\nLast update of the statistics in a table\nDB size\nThe cost of a specific operation in a specific query    . the Execution Plan of an execution plan is the various steps that are involved in fetching results from the database tables. Once a query is executed, the Query Optimizer of the DB Engine quickly generates multiple execution plans and selects the one which returns the results with the best performance. \n\nThere are two types of execution plans\n\nEstimated Execution Plan \u2013 As the name suggests, this type of execution plan is just a guess by the query processor about how the specific steps that are to be involved while returning the results. It is  generated BEFORE the query has been executed and usually generated very quickly. \nActual Execution Plan \u2013 The Actual Execution Plan is generated AFTER the query has been executed. It shows the actual operations and steps involved while executing the query. This may or may not differ from the Estimated Execution Plan. Since this is the actual execution of the SQL Command, it might take a long time for the command to finish. Furthermore, the INSERT / UPDATE and DELETE commands actually modify the data in the tables when the actual plan is executed.  . life Span  span A Span represents a unit of work or operation. Spans are the building blocks of Traces. In OpenTelemetry, they include the following information:\n\nName\nStart and End Timestamps\nSpan Context\nAttributes\nSpan Events\nSpan Links\nSpan Status . digital Insight - An Insight is the interpretation of Metrics. An insight evaluates the status and generates clear problems the user should be aware of, with a reasonable and explainable severity. \n\nAn Insight contains \n\nQuick summary of the problem\nAutomated Investigation - detailed analysis of the thought process, what Metrics were calculated, and how the severity of the problem was evaluated. \nThe Impact of ignoring the problem. \nA Remediation Plan to solve the problem. \nReferences to a Knowledge Base for more information about the problem and how to fix it.   ."
  },
  {
    "text": "Plan Your Implementation  You can implement Metis in a few different ways to ensure it fits with the rest of your tech stack seamlessly, and that it respects the privacy of your organization's data.\n\nAn Illustration of how Metis is integrated at different stages of development by Analyzing SQL Commands Efficiency Locally . The most basic form of analysis Metis offers is done locally on the developers machine.\n\nYou can connect provide Metis a connection to any database with the same schema as your production database, and test the efficiency of queries without actually running them and affecting your database performance or data. . you Test Your Database Code In CI/CD . If you have unit or integration tests running as part of your CI/CD which interact with a database, you can get a report summarizing your database interactions efficiency, issues and the steps required to fix them.\n\nFor your convenience we offer an SDK and GitHub Workflows, to ease integration and present reports inside your pull request page. . relational Database Machine Metrics : You can connect Metis to your database machine in order to observe, analyze and get insights about your the efficiency of your machine.\n\nWhen changes in efficiency are detected, Metis can point out what caused the change, whether a new sub-optimal SQL Command read a large number of table rows and hurt the CPU Usage, or a frequently accessed table grew and an Index creation is required to deal with the new volume. . high Production Observability : Metis offers two ways to observe your production database in order to analyze performance.\n\nProduction Metadata Collector (PMC)\n\nFor those who don't want to install extra SDKs in their production server, we offer another solution. \n\nBy setting up the PMC, you enable Metis to collect metadata such as the general structure, usage and statistics of the production database. Metis can then be configured to simulate  how different SQL Commands would run in production without affecting production performance, or running the risk of exposing production data. . to Install Metis SDK , Installing our SDK in your production server enables Metis to collect all relevant data required to analyze and understand how your database perform in production.\n\nMetis does not collect sensitive data like the parameters in which sql commands ran with, or the values within the returned rows from a query run.\n\nProduction Metadata Collector (PMC)\n\nFor those who don't want to install extra SDKs in their production server, we offer another solution. \n\nBy setting up the PMC, you enable Metis to collect metadata such as the general structure, usage and statistics of the production database. Metis can then be configured to simulate  how different SQL Commands would run in production without affecting production performance, or running the risk of exposing production data.\n\nFor better analysis of your production database we recommend installing the SDK, as it gives much more accurate results. . the Schema Migration Guard . As developers, we know how intimidating it can be to change your database schema while being live.\n\nHaving a PMC configured enables Metis to detect upcoming changes in database schemas that can potentially break production. Metis then alerts you, and gives you the solution to remediate the issue. ."
  },
  {
    "text": "General  a Great Developer Experience (DX) the Metis CLI was built by developers for developers. To provide a great DX the CLI has: \n\nAutocomplete - So you won't need to remember the commands and their parameters\nBuilt-in help. Run doc(command-name)  to see a detailed explanation, with examples, of how to use each command. \nColors and text boxes for easy reading.\nSeamless integration with the web app for a deeper analysis and great visualization.  . the \"Classic\" CLI Mode . The CLI can be used in a \"classic\" CLI mode , running the commands with parameters, seperated by spaces. \n\nFor ex. adding a new connection to a Postgres server\n\nmetis add-connection \"connection-name\" \"postgres\" \\\n\"postgresql://user:password@1.2.3.4:5432/database-name\" \\\n\"connection-description\" . the Main Features : Connect to a Postgres DB, MySQL is coming soon. \nAnalyze a query. The CLI uses the execution plan and schema to generate insights and recommendations. \nMonitor the DB using built-in useful commands\nIndex Analysis - coming soon\n\nThe CLI is a great solution for ad-hoc analysis of queries. Metis Web App is the recommended solution for analyzing the quality of a new version of the application.  . just Getting Started with Metis CLI .  \" in CLI Mode or REPL Mode , The CLI can work in two modes: \n1. A classic single-line CLI command \n2. An interactive CLI\n\nThe single-line CLI was built for automation, a single command contains all the necessary information to execute. While the interactive mode allows the user to explore the data.  . what About to Analyze query performance.\nView the schema. Detect problems and violations of best practices\nConnect to an AWS RDS to view its configuration and performance\nConnect to an AWS RDS to view the query log\n\nThe current version of the Metis CLI supports only Postgres 12 or higher. MySQL 8 support is coming soon.  . in REPL Mode , step 1 - open the REPL CLI  \n\nTo open Metis CLI in REPL mode, just call the CLI\n\nStep 2: run the command as a function, parameters are separated by commas. \n\naddConnection(\"connection-name\", \"postgres\", \"postgresql://user:password@1.2.3.4:5432/database-name\",  \"connection-description\") ."
  },
  {
    "text": "Advanced  step 3. Check for Success ! Open Up Metis Recent Activity to view your insights! ! Metis SDK supports Prisma ORM, Node.js and Express.\n\nYou will need your project token for initializing your library. You can get your project token from Projects Page. other Environment Variables : METIS_API_KEY\n<String> API Key to use\nMETIS_ENVIRONMENT\n<String> Text used to identify the source that sends the instrumentation data.\nWe suggest you Read This Page to fully understand this feature\nMETIS_DISABLED\n<Boolean> If True Metis Instrumentation is fully disabled. We strongly advise to disable the instrumentation when in production to prevent sensitive data from leaving your organization's database.\nMETIS_SERVICE_NAME\n<String> Gives ability to distinguish between services. Useful when working with Micro Services. . step 1. Install . Run the following command to install the SDK using npm-\n\nnpm install --save @metis-data/prisma-interceptor\n\nOpen your prisma.schema and add to your generator client struct the following line-\n\ngenerator client {\n  ...\n  previewFeatures = [\"tracing\"] // Add this line.\n}\n\nRun the following command-\n\nprisma generate\n\nCreate a file named tracer.ts, which will contain your Metis setup code. . type 2. Send Data . Now you can run your application as you normally would, and interact with it in a manner that causes the server to interact with your database. . TypeScript\nimport opentelemetry from '@opentelemetry/api';\nimport { HttpInstrumentation } from '@opentelemetry/instrumentation-http';\nimport { registerInstrumentations } from '@opentelemetry/instrumentation';\nimport { Resource } from '@opentelemetry/resources';\nimport {\n  BasicTracerProvider,\n  BatchSpanProcessor,\n  ConsoleSpanExporter,\n  SimpleSpanProcessor,\n} from '@opentelemetry/sdk-trace-base';\nimport { SemanticResourceAttributes } from '@opentelemetry/semantic-conventions';\nimport { AsyncHooksContextManager } from '@opentelemetry/context-async-hooks';\nimport {\n  createFilter,\n  getPrismaInstrumentation,\n  markSpan,\n  getMetisExporter,\n} from '@metis-data/prisma-interceptor';\nimport { IncomingMessage } from 'http';\n// @ts-ignore\nBigInt.prototype.toJSON = function () {\n    return this.toString();\n};\nexport const StartMetisInstrumentation = (\n  apiKey: string = process.env.METIS_API_KEY,\n  serviceName: string = process.env.METIS_SERVICE_NAME,\n  serviceVersion: string = process.env.npm_package_version,\n  environmentName: string = process.env.METIS_ENVIRONMENT,\n  enabled: boolean = process.env.METIS_DISABLED === 'false') => {\n  const tracerProvider = new BasicTracerProvider({\n    resource: new Resource({\n      [SemanticResourceAttributes.SERVICE_NAME]: serviceName,\n      [SemanticResourceAttributes.SERVICE_VERSION]: serviceVersion,\n    }),\n  });\n  const metisExporter = getMetisExporter(apiKey, environmentName, enabled);\n  tracerProvider.addSpanProcessor(new BatchSpanProcessor(metisExporter));\n  const contextManager = new AsyncHooksContextManager().enable();\n  opentelemetry.context.setGlobalContextManager(contextManager);\n  tracerProvider.register();\n  const urlsFilter = createFilter([/favicon.ico/]);\n  registerInstrumentations({\n    instrumentations: [\n      new HttpInstrumentation({\n        ignoreOutgoingRequestHook: () => true,\n        ignoreIncomingRequestHook: (request: IncomingMessage) => {\n          return urlsFilter(request.url);\n        },\n        requestHook: markSpan,\n      }),\n      getPrismaInstrumentation(),\n    ],\n  });\n};"
  },
  {
    "text": "Connect to AWS  The guide demonstrates how to create an AWS IAM User which will be used by Metis in order to collect metrics from an AWS RDS. These metrics are used by Metis' algorithms to find, understand and fix database performance issues. version 3. Connect CLI to created AWS User , Open Metis-CLI in REPL Mode, type aws_configure() and enter the Access Key ID,  Secret Access Key and Region from the previous step. . version 2. Create IAM User , Create an IAM User, name it Metis, and select Access Key credentials type.\n\n2. Attach MetisPolicy created in the previous step.\n\n3. Clicking 'Next' until you reach the last step and copy the Access Key ID and Secret Access Key. . step 4. Test your Connection to Open Metis-CLI and type to test the AWS RDS integration.\n\naws_rds_get_metrics('rds-name', 'CPUUtilization', 1, 60) . section 1. Set Up IAM Policy : To start, go to Create IAM policy, name the new policy MetisPolicy, select JSON and paste the following policy:\n\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\":\n        [\n            {\n                \"Action\": [\n                    \"cloudwatch:GetMetricStatistics\"\n                ],\n                \"Effect\": \"Allow\",\n                \"Resource\": \"*\"\n            },\n            {\n                \"Action\": [\n                    \"rds:DescribeDBParameters\"\n                ],\n                \"Effect\": \"Allow\",\n                \"Resource\": \"arn:aws:rds:*:*:pg:*\"\n            },\n            {\n                \"Action\": [\n                    \"rds:DescribeDBClusters\"\n                ],\n                \"Effect\": \"Allow\",\n                \"Resource\": \"arn:aws:rds:*:*:cluster:*\"\n            }\n        ]\n}\n\nThis policy grants Read Only access to the following resources-\n\nRDS metadata.\nCloudWatch metrics. \" \" Congratulations!  \" Your AWS RDS database is now connected to Metis. \""
  },
  {
    "text": "Tests  Developers can add their own custom tags to spans. For example, a developer can add a tag with the branch name and commit hash so the span could be correlated to a specific version of your application.\n\nThe developer can add a tag from code (see documentation in each language specific SDK), or using environment variables.\n\nTo add a tag using environment variables you must export a variable with a name that starts with METIS_TAG. For example: \n\nexport METIS_TAG_PR=$(git log -1 --format=\"%H\")\n\nThe span will have an additional tag named pr. "
  },
  {
    "text": "Commands List  dynamic indexAnalysis (static-analysis) . run static analysis on table . oral Arguments . name (string) - the name of the scenario to run, required . to connect (connection) : The 'connect' action connects to a given connection by name. If the connection exists, the tables, and their additional information would be pulled from the database. The connection is not actually kept open. A connection will be made whenever a request to the database is made. . the listConnections (connection) below show the existing connections . oral Arguments . mode (string) - the mode, one of: [pretty, json, silent], default: \"pretty\", required . le descRule (describe) . describe a rule by given id . el config (repl) : prints the current configuration . the withProgress (repl) format enables printing of progress bars . the updateConnectionName (connection) can Change the name of a given connection . current logo (repl) - prints the logo . the testConnection (connection) to test the given connection . other Options user name (string) - the name of the updated connection\ntype (string) - the type of the updated connection\nusername (string) - the user name for the updated connection\npassword (string) - the password for the updated connection\nhost (string) - the host for the updated connection\nport (number) - the port for the updated connection\ndescription (string) - the updated connetion description . oral Arguments . path (string) - path to macro file, required . - generateDocs (repl) - generate markdown documentation file from all actions . oral Arguments . args (array) - the cli input, default: [], optional . other Options : showQueries (boolean) - show sql queries\nseverity (enum) - severity of rules to show, default: \"low\", values: [\"critical\", \"high\", \"medium\", \"low\", \"info\"] . oral Arguments . connectionName (string) - the name of the connection, required . oral Arguments . twoPartName (string) - name of the database and table connected with a dot, required . el testScenario (test) : run a scneario . oral Arguments . actionName (string) - the name of the action to print, required . the resetLogCollector (logs) can Clear all logs from log file . oral Arguments : tableName (string) - table name, required . query listFunctions (query-analysis) : Show the User Defined Functions (UDF) in the DB . current Usage of Javascript\n\nupdateConnectionName(\"old-connection-name\", \"new-connection-name\")\n\nShell\n\nmetis update-connection-name \"old-connection-name\" \"new-connection-name\" . current Usage : Javascript\n\ntempConnect(\"Server=myServer.com;Database=myDB;User Id=myUser;Password=myPass;\", \"mssql\")\n\nShell\n\nmetis temp-connect \"Server=myServer.com;Database=myDB;User Id=myUser;Password=myPass;\" \"mssql\" ; current Usage : Javascript\n\nparse(\"SELECT * FROM table\").\n\nShell\n\nmetis parse \"SELECT * FROM table\" \n\nJavascript\n\nparse(\"SELECT * FROM table\").type(\"mssql\")\n\nShell\n\nmetis parse \"SELECT * FROM table\" --type \"mssql\"\n\nJavascript\n\nparse(\"SELECT * FROM table\").type(\"postgres\")\n\nShell\n\nmetis parse \"SELECT * FROM table\" --type \"postgres\" . the deleteConnection (connection) will remove a given connection from file . - connectPG (connection) - connects to 'aws_pg' . current Usage : Javascript\n\nsqlCmd(\"SELECT * FROM table\").\n\nShell\n\nmetis sql-cmd \"SELECT * FROM table\"  . the getPlan (query-analysis) the get query plan . oral Arguments . path (string) - file path to write the markdown, required . current Usage : Javascript\n\ndescQuery(\"example-package\", \"example-query\").\n\nShell\n\nmetis desc-query \"example-package\" \"example-query\"  . oral Arguments : key (string) - key name, required\nvalue (any) - the value, can be of any type, required . current Usage : Javascript\n\ndescPackage(\"example-package\")\n\nShell\n\nmetis desc-package \"example-package\" . current Usage : Javascript\n\nformat(\"SELECT * FROM table\").\n\nShell\n\nmetis format \"SELECT * FROM table\" \n\nJavascript\n\nformat(\"SELECT * FROM table\").type(\"mssql\")\n\nShell\n\nmetis format \"SELECT * FROM table\" --type \"mssql\"\n\nJavascript\n\nformat(\"SELECT * FROM table\").type(\"postgres\")\n\nShell\n\nmetis format \"SELECT * FROM table\" --type \"postgres\" . the descMetric (describe) notation describes a given metric . query parse (query) : parse a query with a given type and return an object . oral Arguments . connectionName (string) - the name of the connection, required . other Options : filterProps (object) - filters to filter the logs . oral Arguments optional name (string) - the name of the new connection, optional\ntype (string) - the type of the connection, optional\nconnectionString (string) - the connection string, optional\ndescription (string) - the connetion description, optional . oral Arguments . query (string) - the query to format, required . the noProgress (repl) can disable printing of progress bars . current Usage of Javascript\n\nupdateConnectionName(\"old-connection-name\", \"new-connection-name\")\n\nShell\n\nmetis update-connection-name \"old-connection-name\" \"new-connection-name\" . # deleteLogCollector (logs) # Delete log collector . the descTable (describe) function describes a given table . - complete (repl) - exits the REPL . oral Arguments . connectionName (string) - the name of the connection, required . other Options : description (string) - the description of the collector\nconnectionName (string) - the name of the connection to associate with the logs for Silk . english version (repl) : prints the version . oral Arguments required rowNumber (number) - the number of the row that would be used as input of the command, required\ncommandName (string) - the name of the command to run, required . dynamic tableAnalysis (static-analysis) . run static analysis on table . current Usage : Start an add-connection prompt\n\nJavascript\n\naddConnection()\n\nShell\n\nmetis add-connection \n\nAdd a connection with name, type, connection-string and description\n\nJavascript\n\naddConnection(\"localPostgresDB\", \"postgres\", \"postgresql://user:pass@localhost:5432/dbname\", \"Dev Postgres connection\")\n\nShell\n\nmetis add-connection \"localPostgresDB\" \"postgres\" \"postgresql://user:pass@localhost:5432/dbname\" \"Dev Postgres connection\"\n\nJavascript\n\naddConnection(\"mysqlLocalCon\", \"mysql\", \"mysql://root:pass@3.69.95.41:3306/database_name\", \"Dev Mysql connection\")\n\nShell\n\nmetis add-connection \"mysqlLocalCon\" \"mysql\" \"mysql://root:pass@3.69.95.41:3306/database_name\" \"Dev Mysql connection\" ; other Options user name (string) - the name of the updated connection\ntype (string) - the type of the updated connection\nusername (string) - the user name for the updated connection\npassword (string) - the password for the updated connection\nhost (string) - the host for the updated connection\nport (number) - the port for the updated connection\ndescription (string) - the updated connetion description . oral Arguments . query (string) - query to analyze, required . the withProgress (repl) format enables printing of progress bars . - clientMode (repl) . replace func implementation with a REST client func . current Usage : Javascript\n\ndescTable(\"schema.table-name\")\n\nShell\n\nmetis desc-table \"schema.table-name\" ; oral Arguments : id (string) - the id of the rule, required\nfacts (object) - an object containing facts, optional . the viewLogCollector (logs) can view a specific log . oral Arguments . name (string) - log collector name, required . oral Arguments . query (string) - query to analyze, required . the tempConnect (connection) that connects to server using connection string, this connection would not be saved . dynamic indexAnalysis (static-analysis) . run static analysis on table . oral Arguments . twoPartName (string) - name of the database and table connected with a dot, required . other Options : type (string) - select dialect, default: \"mssql\" . oral Arguments . connectionName (string) - the name of the connection, required . the relatedCommand (query) command runs a related command on the last result . oral Arguments . sqlQuery (string) - regular sql query, required . current Usage of Javascript\n\nlogAnalysis(\"logCollectorName\").restCommandType(\"GET\").minSeverity(\"low\")\n\nShell\n\nmetis log-analysis \"logCollectorName\" --rest-command-type \"GET\" --min-severity \"low\"\n\nJavascript\n\nlogAnalysis(\"logCollectorName\").fromDate(\"2022-01-01T10:38:52.209Z\").minSeverity(\"info\")\n\nShell\n\nmetis log-analysis \"logCollectorName\" --from-date \"2022-01-01T10:38:52.209Z\" --min-severity \"info\" . to connect (connection) : The 'connect' action connects to a given connection by name. If the connection exists, the tables, and their additional information would be pulled from the database. The connection is not actually kept open. A connection will be made whenever a request to the database is made. . oral Arguments : logName (string) - the name of the log file, required\nuuid (string) - the uuid of the log, required . oral Arguments : indexName (string) - index name, required . oral Arguments . query (string) - query to analyze , required . other Options : category (string) - select category to show\nsearch (string) - fuzzy search phrase . the disableClientMode (repl) can disable client mode . partial listTestScenarios (test) full show list of test scenarios . current Usage : Javascript\n\nsetDefaultConnection(\"connection-name\")\n\nShell\n\nmetis set-default-connection \"connection-name\" ; the addConnection (connection) to add a new connection . oral Arguments optional name (string) - the name of the new connection, optional\ntype (string) - the type of the connection, optional\nconnectionString (string) - the connection string, optional\ndescription (string) - the connetion description, optional . the productionAgentTableSize (production-agent) can Get the tables size between the connection config and its production . el config (repl) : prints the current configuration . the expressServer (repl) can start an express server based on the actions . final scenario (scenario) : runs a scenario . the listConnections (connection) below show the existing connections . the tableAnalysisReport (describe) and print a report of available facts . - setApiKey (repl) ; add metis api key ; warm welcome (repl) - prints the welcome message . - printMode (repl) - set the print mode . the tableAnalysisReport (describe) and prints a report of available facts . the addLogCollector (logs) will Add a new Log Collector . other Options : port (number) - the server port . oral Arguments : secanrioName (string) - the name of the test scenario, required . el loadScenario (scenario) : load scenarios and save them to state . other Options : filterProps (object) - filters to filter the logs\nminDuration (number) - filter logs by duration (EQUALS_OR_HIGHER_THAN)\nfromDate (string) - filter logs by date\ntoDate (string) - filter logs by date\nrestCommandType (enum) - filter logs rest command (GET or POST), values: [\"GET\", \"POST\", \"PUT\", \"DELETE\", \"OPTIONS\"]\ncommandContains (string) - filter log query which contain the word\nminSeverity (enum) - filter log query by severity, default: \"low\", values: [\"critical\", \"high\", \"medium\", \"low\", \"info\"] . other Options : type (string) - select dialect, default: \"mssql\" . the deleteConnection (connection) will remove a given connection from file . direct help (repl) : prints the description of all available functions . oral Arguments . name (string) - log collector name, required . current Usage : Javascript\n\ndeleteConnection(\"connection-name\")\n\nShell\n\nmetis delete-connection \"connection-name\" ; other Options : name (string) - log collector name\nsource (string) - the url to load the logs from (uri path/file path/silk)\ndescription (string) - the description of the collector\nconnectionName (string) - the name of the connection to associate with the logs for Silk . oral Arguments . apiKey (string) - the metis api key value, required . and sqlCmd (query-analysis) to execute an SQL command . oral Arguments : tableName (string) - table name, required . - loadMacro (repl) - load a macro from a directory . the analyzeQueryByLogID (logs) allows Analysis a specific log by id . oracle sqlCmd (query) . run sql command . list listFunctions (query) : Show the User Defined Functions (UDF) in the DB . the setDefaultConnection (connection) will set the default connection and connects to it . the getPlan (query-analysis) can get an execution plan for a given query . current Usage : Javascript\n\ndescRule(\"QRY000001\")\n\nShell\n\nmetis desc-rule \"QRY000001\"\n\nJavascript\n\ndescRule(\"QRY000001\", { 'actual-rows-read': 1000000 })\n\nShell\n\nmetis desc-rule \"QRY000001\" '{\"actual-rows-read\":1000000}' ; current Usage : Javascript\n\nqueryAnalysis(\"SELECT * FROM TableName\")\n\nShell\n\nmetis query-analysis \"SELECT * FROM TableName\"\n\nClient\n\ncurl -X GET \"http://localhost:3001:3001/query-analysis?query=SELECT%20%2A%20FROM%20TableName\"\n\nJavascript\n\nqueryAnalysis(\"SELECT * FROM TableName\").showPlan(true)\n\nShell\n\nmetis query-analysis \"SELECT * FROM TableName\" --show-plan\n\nClient\n\ncurl -X GET \"http://localhost:3001:3001/query-analysis?query=SELECT%20%2A%20FROM%20TableName&show-plan=true\" ? oral Arguments . name (string) - log collector name, required . query runNamedCmd (query) : runs a given query in a given package . oral Arguments : secanrioName (string) - the name of the scenario test to run, required . - logAnalysis (logs) - analyze logs . the listTables (describe) section prints the tables list for the current connection . oral Arguments the metric (string) - name of the metric, required . the descTable (describe) function describes a given table . current Usage : Start an add-connection prompt\n\nJavascript\n\naddConnection()\n\nShell\n\nmetis add-connection \n\nAdd a connection with name, type, connection-string and description\n\nJavascript\n\naddConnection(\"localPostgresDB\", \"postgres\", \"postgresql://user:pass@localhost:5432/dbname\", \"Dev Postgres connection\")\n\nShell\n\nmetis add-connection \"localPostgresDB\" \"postgres\" \"postgresql://user:pass@localhost:5432/dbname\" \"Dev Postgres connection\"\n\nJavascript\n\naddConnection(\"mysqlLocalCon\", \"mysql\", \"mysql://root:pass@3.69.95.41:3306/database_name\", \"Dev Mysql connection\")\n\nShell\n\nmetis add-connection \"mysqlLocalCon\" \"mysql\" \"mysql://root:pass@3.69.95.41:3306/database_name\" \"Dev Mysql connection\" ; other Options : showFormattedSql (boolean) - show formatted SQL, default: true\nshowPlan (boolean) - show simplified execution plan\nshowExplain (boolean) - show explain information\nshowMetrics (boolean) - show the facts gathered from the execution plan, default: true\nshowTableInfo (boolean) - show table info, default: true\nshowTableIndexInfo (boolean) - show table index/es info\nshowInsights (boolean) - show insights information, default: true\nrouteName (string) - route name, default: \"metis/cli/queryAnalysis\"\ntag (string) - tag name, default: \"PR\"\nshowAllInsights (boolean) - show all the insight include skipped, success, low, very low and info, default: true\nexecPlanType (enum) - run execution plan with chosen mode actual/estimated, default: \"Estimated\", values: [\"Actual\", \"Estimated\"]\nshowMetricsDiff (boolean) - show the diff between all the existing metrics to the generated metrics . the descPackage (describe) model describes a given package . jean descQuery (describe) : describes a given query . the descMetric (describe) functions describe a given metric . oral Arguments : connectionName (string) - the name of the connection, required\nnewConnectionName (string) - the new name for the connection, required . direct help (repl) : prints the description of all available functions . to generateBashCompletions (repl) . generate a completion file for bash . current Usage : Javascript\n\ndescTable(\"schema.table-name\")\n\nShell\n\nmetis desc-table \"schema.table-name\" ; oral Arguments . exitCode (number) - the exit code that would be used when terminating the process, optional . oral Arguments : indexName (string) - index name, required . - printMode (repl) - set the print mode . the editConnection (connection) to edit a connection . the editConnection (connection) to edit a connection . his Actions .  ' oral Arguments : id (string) - the id of the rule, required\nfacts (object) - an object containing facts, optional . see addPcmToConnection (connection) to add PCM to an exsiting connection . other Options : showQueries (boolean) - show sql queries\nseverity (enum) - severity of rules to show, default: \"low\", values: [\"critical\", \"high\", \"medium\", \"low\", \"info\"] . el descTestScenario (test) to show test scenario cases names and details . oral Arguments . connectionName (string) - the name of the connection, required . the doc (repl) format prints the description of an action . the queryAnalysis (query) or The 'queryAnalysisPG' action runs an analysis on a given query. The output can be controlled using option parameters. . current Usage : Javascript\n\nconnect(\"connection-name\")\n\nShell\n\nmetis --connect \"connection-name\"\n\nClient\n\ncurl -X GET \"http://localhost:3001:3001/connect?connection-name=connection-name\" \" no exit (repl) no exits the REPL . oral Arguments : log-collector-name (string) - log collector name, required . the resetConnectionsFile (connection) will delete all connections from the file . the addConnection (connection) to add a new connection . oral Arguments : connectionName (string) - the name of the connection, required\npcmConnectionString (string) - connetion string for PCM, required . the editLogCollector (logs) and Edit log collector . oral Arguments . connectionName (string) - the name of the connection, required . oral Arguments . connectionName (string) - the name of the connection, required . other Options : showQueries (boolean) - show sql queries\nseverity (enum) - severity of rules to show, default: \"low\", values: [\"critical\", \"high\", \"medium\", \"low\", \"info\"] . other Options : category (string) - select category to show\nsearch (string) - fuzzy search phrase . le descRule (describe) . describe a rule by given id . oral Arguments . connectionName (string) - the name of the connection, required . the testConnection (connection) to test the given connection . current Usage : Javascript\n\ndeleteConnection(\"connection-name\")\n\nShell\n\nmetis delete-connection \"connection-name\" ; oral Arguments . sqlQuery (string) - regular SQL query, required . oral Arguments . package (string) - the name of the package, required . the disconnect (connection) the disconnect from the current connection . - editConfig (repl) - edit/add key and value to config . oral Arguments . query (string) - the query to parse, required . query format (query) query formats a query . inventory inventory (describe) : prints the inventory . oral Arguments . query (string) - query to analyze , required . current Usage : Javascript\n\ndescRule(\"QRY000001\")\n\nShell\n\nmetis desc-rule \"QRY000001\"\n\nJavascript\n\ndescRule(\"QRY000001\", { 'actual-rows-read': 1000000 })\n\nShell\n\nmetis desc-rule \"QRY000001\" '{\"actual-rows-read\":1000000}' ; - currentState (repl) - prints the current state . dynamic tableAnalysis (static-analysis) . run static analysis on table . oral Arguments . file (string) - the file out path, required . the listTables (describe) : print the tables list for the current connection . oral Arguments : pkg (string) - the package name, required\nquery (string) - the query name, required\nparameters (object) - JSON containing the parameters, optional . oral Arguments : connectionName (string) - the name of the connection, required\nnewConnectionName (string) - the new name for the connection, required . oral Arguments . connectionName (string) - the name of the connection, required . the noProgress (repl) can disable printing of progress bars . oral Arguments source name (string) - log collector name, required\nsource (string) - the url to load the logs from (uri path/file path/silk), required\ndescription (string) - the description of the collector, optional\nconnectionName (string) - the name of the connection to associate with the logs for Silk, optional . current Usage : Javascript\n\nqueryAnalysis(\"SELECT * FROM TableName\")\n\nShell\n\nmetis query-analysis \"SELECT * FROM TableName\"\n\nJavascript\n\nqueryAnalysis(\"SELECT * FROM TableName\").showPlan(true)\n\nShell\n\nmetis query-analysis \"SELECT * FROM TableName\" --show-plan . oral Arguments . actionName (string) - the name of the action to print, required . oral Arguments . connectionName (string) - the name of the connection, required . oral Arguments required package (string) - the name of the package, required\nquery (string) - the name of the query, required . other Options : showQueries (boolean) - show sql queries\nseverity (enum) - severity of rules to show, default: \"low\", values: [\"critical\", \"high\", \"medium\", \"low\", \"info\"] . the reloadConnections (connection) the reload connections . oral Arguments : connectionString (string) - the connection string, required\nconnectionType (string) - the connection type, required . the queryAnalysis (query-analysis) is The 'queryAnalysisPG' action runs an analysis on a given query. The output can be controlled using option parameters. . the doc (repl) format prints the description of an action . current Usage : Javascript\n\nrunNamedCmd(\"example-package\", \"example-query\").\n\nShell\n\nmetis run-named-cmd \"example-package\" \"example-query\" \n\nJavascript\n\nrunNamedCmd(\"example-package\", \"example-query\").param(\"value\")\n\nShell\n\nmetis run-named-cmd \"example-package\" \"example-query\" --param \"value\" . oral Arguments . path (string) - path of the scenario file to load, optional . current Usage : Javascript\n\nconnect(\"connection-name\")\n\nShell\n\nmetis --connect \"connection-name\" . the listPackages (describe) : list the packages that are relevant for the current connection, or all if no connection is set . oral Arguments . mode (string) - the mode, one of: [pretty, json, silent], default: \"pretty\", required . current Usage : Javascript\n\nrelatedCommand(0, \"related-command-name\").\n\nShell\n\nmetis related-command 0 \"related-command-name\"  . other Options : showFormattedSql (boolean) - show formatted SQL, default: true\nshowPlan (boolean) - show simplified execution plan\nshowExplain (boolean) - show explain information\nshowMetrics (boolean) - show the facts gathered from the execution plan, default: true\nshowTableInfo (boolean) - show table info, default: true\nshowTableIndexInfo (boolean) - show table index/es info\nshowInsights (boolean) - show insights information, default: true\nshowAllInsights (boolean) - show all the insight include skipped, success, low, very low and info, default: true\nexecPlanType (enum) - run execution plan with choosen mode actual/estimated, default: \"Actual\", values: [\"Actual\", \"Estimated\"]\nshowMetricsDiff (boolean) - show the diff between all the exist metrics to the generate metrics . the listLogCollectors (logs) will List all existing Log Collectors . the updateConnectionName (connection) will update the connection name . oral Arguments the metric (string) - name of the metric, required . current Usage : Javascript\n\nsqlCmd(\"SELECT * FROM table\").\n\nShell\n\nmetis sql-cmd \"SELECT * FROM table\"  ."
  },
  {
    "text": "Under the Hood  Metis provides an end-to-end solution to easily detect db-related problems before they hit production. For that Metis needs to collect the SQL commands and relevant data. Then it processes the raw data into clear insights which explain the users what went wrong and how to fix that.     in Generating the Insights  , The Backend processes the stream of traces. It runs automatic checks for rule violations and misconfiguration of the database. When rule violations are found, Metis produces an insight which guides the developer to fix the issue while explaining the reason behind the rule.  . OpenTelemetry\nThe SDK generates a Trace, the REST command caller and every SQL command generated in the code. The technical implementation is a Span (part of a Trace) for the REST command and more Spans for each SQL command, all using the same Trace ID, to allow the backend to show all the spans in the same context.\nGenerating Traces in the code is now a simple task using OpenTelemetry. OpenTelemetry is an open source, vendor agnostic, collection of tools, APIs, and SDKs. It is used to instrument, generate, collect, and export telemetry data (metrics, logs, and traces) to help you analyze your software\u2019s performance and behavior.\nOpenTelemetry provides SDKs for all major Frameworks and ORMs. \n\nAnother interesting feature in OpenTelemetry is SQLCommenter. SQLCommenter is a suite of middleware / plugins that enable your ORMs to augment SQL statements before execution, with comments containing information about the code that caused its execution. This helps in easily correlating slow performance with source code and giving insights into backend database performance. In short, it provides some observability into the state of your client-side applications and their impact on the database\u2019s server-side.\n\nSELECT\n    booking.title AS booking_title\nFROM \n    booking\n    /*traceparent='00-59888198e0d98e0d9c1e72d4def4387019030-5fd1362f8aa2affe-1'*/ Explain about PMC, data flow, Emphasize here we don't use the data and don't impact performance. \n\nMetis' SDKs enable an automatic sending of SQL commands for analysis.\n\nThe instrumentation and configuration are very simple and can be implemented using a few lines of code. It is similar to the instrumentation of other monitoring SDKs you probably implemented already. \n\nThe SDK works well with ORMs, there is no need to search for the SQL command, as the SDK automatically maps all the SQL commands related to any REST or GraphQL request.  then The Flow is:  first Sign Up to Metis to get an API Key. The first API Key is created automatically, later you can generate more keys. \nInstall the SDK for your Middleware / ORM. See below the supported options\nInstrument your code to collect the SQL commands and send them to Metis. \nOpen the web app to review the Insights: problems and how to solve them.  . by Viewing the Insights , The web app shows the traces sent from the users' app servers via the SDK. The users can see an overview of the recent QA tests, and quickly identify the REST commands which generated bad SQL. The web app provides deep SQL command analysis, showing all the insights related to the SQL. The insights are easy to understand and contain a remediation plan for the problem.  . the Metis SDK Instrumentation  : Metis provides an SDK for popular ORM and Middlewares, such as Python SQL Alchemy or JS Sequelize. The SDK provides simple installation and instrumentation with almost no impact on performance. The SDK uses only metadata about the db schema and query activity is needed. \n\nThe SDK generates Traces that link the caller REST or GraphQL with the SQL command(s) it generated. The SDK uses OpenTelemetry to generate the traces. That allows Metis easy integration with existing Open Telemetry instrumentation and other Application Performance Monitoring (APM) tools. \n\nOn top of the traces, the SDK also sends Metis the execution plan of the SQL commands, the schema of the relevant tables and indexes, tables size, and index usage.  ."
  },
  {
    "text": "REPL  eyes Open view metis-cli\n\nView All Supported Commands\n\nhelp()\n\nView detailed help of a specific command.\n\ndoc(command-name) . You can also work with mets-cli in REPL mode. This allows for a more continuous work flow that's more convenient to some developers while investigating issues. - Auto Complete - Some of the commands has built-in auto complete. When you start typing, the CLI suggest parameter's values or relevant objects. You can also click twice on TAB to see all relevant options. \n\nExample - The command connect() expects an existing connection name to a database. The auto completion suggests a connection name from the list of existing connections. Tapping TAB twice will show all possible connections.\n\nAuto Complete ."
  },
  {
    "text": "Pull Requests  Coming Soon"
  },
  {
    "text": "Tutorials  Here you can find a few end-to-end tutorials, to get a better understanding of how to use Metis. "
  },
  {
    "text": "Getting Started  step 1. Sign Up . Through here . This is a guide to get up and running with Metis. version 3. Install SDK : The following guide will lead you through choosing the right SDK for you and link to your project. . step 2. Create a Project . In order to get your API Key you need to create a project-\n\nProjects Page ."
  },
  {
    "text": "JavaScript - Prisma  historical Overview : Metis offers database observability for developers who use Prisma ORM.\n\nCheck out our Prisma Advanced Guide for additional advanced configurations and use cases. . TypeScript\n/*tracing.ts*/\nimport opentelemetry from \"@opentelemetry/api\";\nimport { HttpInstrumentation } from \"@opentelemetry/instrumentation-http\";\nimport { NestInstrumentation } from \"@opentelemetry/instrumentation-nestjs-core\";\nimport { registerInstrumentations } from \"@opentelemetry/instrumentation\";\nimport { Resource } from \"@opentelemetry/resources\";\nimport {\n  BasicTracerProvider,\n  ConsoleSpanExporter,\n  SimpleSpanProcessor,\n} from \"@opentelemetry/sdk-trace-base\";\nimport { SemanticResourceAttributes } from \"@opentelemetry/semantic-conventions\";\nimport { AsyncHooksContextManager } from \"@opentelemetry/context-async-hooks\";\nimport {\n  getPrismaInstrumentation,\n  createFilter,\n  markSpan,\n  MetisRemoteExporter,\n} from \"@metis-data/prisma-interceptor\";\nimport { IncomingMessage } from \"http\";\nexport const tracerProvider = new BasicTracerProvider({\n  resource: new Resource({\n    [SemanticResourceAttributes.SERVICE_NAME]: \"test-tracing-service\",\n    [SemanticResourceAttributes.SERVICE_VERSION]: \"1.0.0\",\n  }),\n});\nexport const metisExporter = new MetisRemoteExporter(\n  process.env.EXPORTER_URL,\n  process.env.EXPORTER_API_KEY,\n  {},\n);\ntracerProvider.addSpanProcessor(new SimpleSpanProcessor(metisExporter));\ntracerProvider.addSpanProcessor(\n  new SimpleSpanProcessor(new ConsoleSpanExporter()),\n);\nconst contextManager = new AsyncHooksContextManager().enable();\nopentelemetry.context.setGlobalContextManager(contextManager);\ntracerProvider.register();\nconst urlsFilter = createFilter([/favicon.ico/]);\nexport const uninstrument = registerInstrumentations({\n  instrumentations: [\n    new HttpInstrumentation({\n      ignoreOutgoingRequestHook: () => true,\n      ignoreIncomingRequestHook: (request: IncomingMessage) => {\n        return urlsFilter(request.url);\n      },\n      requestHook: markSpan,\n    }),\n    new NestInstrumentation(),\n    getPrismaInstrumentation(),\n  ],\n}); version 2. Run Application . Now you can run your application as you normally would, and interact with it in a manner that causes the server to interact with your database. . Coming Soon step 3. Check for Success . After a while you should see activity in your Project's . . Metis SDK supports Prisma ORM with the following frameworks- sustainable Development _ METIS_TAG=DEVELOPMENT . system Configuration Parameters - SERVICE_NAME\nA short name to easily group data coming from the service.\norders-service\nSERVICE_VERSION\nOptional. An internal version of the service, to help the developers to distinguish between data from different versions.\n1.2.3\nAPI_KEY\nYour project's API key.\nz9bayHMU69amS9KmdjnTo1bqVqoX1Fa11IlRp2Aq . type 2. Send Data . Now you can run your application as you normally would, and interact with it in a manner that causes the server to interact with your database. . step 1. Install - Use the following to install into a project using NPM.\n\nnpm install --save @metis-data/prisma-interceptor\n\nCreate a file named tracing.ts|js, which will contain your Metis setup code. . type 2. Send Data . Now you can run your application as you normally would, and interact with it in a manner that causes the server to interact with your database. . 1. Install\nnpm install --save @metis-data/prisma-express-interceptor\n\nOpen your prisma.schema and add to your generator client struct the following line-\n\ngenerator client {\n  ...\n  previewFeatures = [\"tracing\"] // Add this line.\n}\n\nThe following code, has to run before your server starts listening-\n\nimport { PrismaClient } from '@prisma/client';\nimport { PrismaExpressInterceptor } from '@metis-data/prisma-express-interceptor';\nBigInt.prototype.toJSON = function () {\n  return this.toString();\n};\nconst prisma = new PrismaClient({\n  log: [\n    {\n      emit: 'event',\n      level: 'query',\n    },\n  ],\n});\nconst interceptor = PrismaExpressInterceptor.create({\n  serviceName: '<SERVICE_NAME>',\n  api_key: '<API_KEY>',\n  serviceVersion: '<SERVICE_VERSION>'\n});\ninterceptor.instrument(\n  prisma, // The application Prisma client\n  {\n    excludedUrls: [], // Add URLs regex to ignore here\n    printToConsole: false, // Print outgoing spans in console (default to false)\n  }\n);\n// Make sure to import express after instrumenting prisma.\nimport express from 'express';\nconst app = express();\napp.use(express.json());\napp.get('/hello', async (req, res) => {\n  return res.send('hello world');\n});\n\nMake sure to import express after instrumenting prisma. other Environment Variables : METIS_INSTRUMENTATION\nSet false to stop all data collection, any other value activates Metis. ; java JavaScript ;  ; step 1. Initialize the Library . You will need your project token for initializing your library. You can get your project token from Projects Page.\n\nUse the following to install into a project using NPM.\n\nnpm install --save @metis-data/prisma-interceptor\n\nCreate a file named tracing.ts|js, which will contain your Metis setup code. . post Production _ METIS_TAG=PRODUCTION . st John's Local Enviroment = METIS_ENVIRONMENT=JOHN_LOCAL . st John's Local Enviroment _ METIS_TAG=JOHN_LOCAL . sustainable Development = METIS_ENVIRONMENT=DEVELOPMENT . TypeScript\n/*tracing.ts*/\nimport opentelemetry from \"@opentelemetry/api\";\nimport { HttpInstrumentation } from \"@opentelemetry/instrumentation-http\";\nimport { NestInstrumentation } from \"@opentelemetry/instrumentation-nestjs-core\";\nimport { registerInstrumentations } from \"@opentelemetry/instrumentation\";\nimport { Resource } from \"@opentelemetry/resources\";\nimport {\n  BasicTracerProvider,\n  ConsoleSpanExporter,\n  SimpleSpanProcessor,\n} from \"@opentelemetry/sdk-trace-base\";\nimport { SemanticResourceAttributes } from \"@opentelemetry/semantic-conventions\";\nimport { AsyncHooksContextManager } from \"@opentelemetry/context-async-hooks\";\nimport {\n  getPrismaInstrumentation,\n  createFilter,\n  markSpan,\n  MetisRemoteExporter,\n} from \"@metis-data/prisma-interceptor\";\nimport { IncomingMessage } from \"http\";\nexport const tracerProvider = new BasicTracerProvider({\n  resource: new Resource({\n    [SemanticResourceAttributes.SERVICE_NAME]: \"test-tracing-service\",\n    [SemanticResourceAttributes.SERVICE_VERSION]: \"1.0.0\",\n  }),\n});\nexport const metisExporter = new MetisRemoteExporter(\n  process.env.EXPORTER_URL,\n  process.env.EXPORTER_API_KEY,\n  {},\n);\ntracerProvider.addSpanProcessor(new SimpleSpanProcessor(metisExporter));\ntracerProvider.addSpanProcessor(\n  new SimpleSpanProcessor(new ConsoleSpanExporter()),\n);\nconst contextManager = new AsyncHooksContextManager().enable();\nopentelemetry.context.setGlobalContextManager(contextManager);\ntracerProvider.register();\nconst urlsFilter = createFilter([/favicon.ico/]);\nexport const uninstrument = registerInstrumentations({\n  instrumentations: [\n    new HttpInstrumentation({\n      ignoreOutgoingRequestHook: () => true,\n      ignoreIncomingRequestHook: (request: IncomingMessage) => {\n        return urlsFilter(request.url);\n      },\n      requestHook: markSpan,\n    }),\n    new NestInstrumentation(),\n    getPrismaInstrumentation(),\n  ],\n}); to Declare Environment , Your Project Token can be used by your organization in different places, by different developers. In order to be able to distinguish the different sources and of data, we require adding an environment variable METIS_TAG. For example:  . java JavaScript ;  ; post Production = METIS_ENVIRONMENT=PRODUCTION . step 3. Check for Success ! Open Up Metis Recent Activity to view your insights! !"
  },
  {
    "text": "Set Up  Deploy PMC using CloudFormation\nOpen our CloudFormation Template and use the following guide-\n\nMake sure the following link populates the field Template URL\n\nAWS Quick Create Stack\n\n2. Name the stack. The default name is MetisMetadataCollector.\n\n3. Enter a valid Cluster Name where you want to launch the PMC. \n\n4. Enter the Connection string to the database you would like to collect metadata from, in the following pattern-\n\npostgresql://user:password@host:port/database_name\n\nYou can also collect metadata from multiple databases by chaining multiple Connection Strings with a ; between them.\n\nFor Example- \n\npostgresql://user:password@host:port/database_name;postgresql://user:password@host:port/database_name;postgresql://user:password@host:port/database_name;postgresql://user:password@host:port/database_name\n\n4. Enter your API Key in MetisAPIKey field.\n\n5. Choose a Security Group, make sure it has access to your database. \n\n6. Choose a Subnet ID. If you run your database on AWS, make sure it's in the same VPC as your database's VPC.\n\n7. Select the 3 checkboxes to acknowledge the AWS operations. \n\nClick on Create Stack. Only Postgres 12 and higher is supported."
  },
  {
    "text": "Trace Details  Each Rest API Command received from the SDK is analyzed by Metis and insights are derived. To react the Trace Details Page, click one of the traces in the recent activity table.\n\nTrace Details\n\nThe Timeline component consists of all SQL Commands executed as part of this trace.\n\nAfter selecting an SQL command from the Timeline component, you can through the different tabs to further investigate-\n\nInsights \n\nThe list of derived insights for the selected SQL Command.\n\nSQL\n\nThe actual SQL Command code.\n\nMetrics\n\nDifferent measurments taken by Metis to perform the analysis.\n\nQuery Tale\n\nA visualization of the Execution Plan.\n\nExecution Plan\n\nThe raw Execution Plan, in JSON format.\n\nTables\n\nDetails on which table was accessed using which method."
  },
  {
    "text": "Analyzing a Query  information About Query Analysis : The command queryAnalysis() expects a valid SQL command. \n\nThe SQL command runs using the currently open connection, there is no need to explicitly specify its name. If you work in CLI mode, then the command uses the connections configured as the default one.  . music Features and Information about each table used by the query.\nThe Execution Plan.\nThe Metrics calculated from the Execution Plan, DB Schema and Data.\nInsights evaluated from the metrics.\nWeb app link for more information. . - CLI - metis-cli query-analysis \"select count (*) from sales.order_lines where quantity > 315\" --show-plan . for Example 4 - Show the Metrics and The Metrics . & REPL . queryAnalysis(\"select count (*) from sales.order_lines where quantity > 315\").showPlan(true) . compare Actual vs Estimated Plan . We recommend you go over our actual vs estimated plan explanation here-\n\nBy default, the CLI uses the estimated plan. . The command queryAnalysis()expects a valid SQL command. \n\nThe SQL command runs using the currently open connection (The Default Connection, or the connection you've connected to in REPL Mode), there is no need to explicitly specify its name. & REPL . queryAnalysis(\"select count (*) from sales.order_lines where quantity > 315\") ; a Multi-Line SQL Command used To analyze queries that do not fit in one line use a variable-\n\nmy_query=\"select * from postgres_air.flight limit 100\"\nmetis-cli query-analysis \"$my_query\" . for Example 3 - Multi-Line SQL Command used To analyze queries that do not fit in one line use a variable.\n\nmy_query=\"select * from postgres_air.flight limit 100\"\nmetis-cli query-analysis \"$my_query\" . for Example 1  ;  ; when Analyzing a Query .  . see Example 2 . Analyze a query, and show the execution plan too . - CLI - metis-cli query-analysis \"select count (*) from sales.order_lines where quantity > 315\" . for Example 5 - Help users Use the .help() function to learn about all the properties and what parameters they expect\n\nREPL: queryAnalysis().help()\n\nCLI: metis query-analysis -h\n\nqueryAnalysis().help() (REPL)\n\nquery-analysis -h (CLI) ."
  },
  {
    "text": "CLI - Query Analysis  to Analyze a query  , Analyze a query using the command queryAnalysis.  The command generates the estimated execution plan. The CLI shows a quick analysis of the query and also sends the data to Metis Web App.  \n\nqueryAnalysis(\"SQL_QUERY\")\n\nfor ex. \n\nqueryAnalysis(\"select * from postgres_air.boarding_pass as b where passenger_id = 4484037\")\n\nYou can also analyze the query using the actual execution plan.  \n\nqueryAnalysis(\"select * from postgres_air.boarding_pass as b where passenger_id = 4484037\").execPlanType(\"Actual\")va\n\nThe CLI prints a basic query analysis . to Configure an API Key , The CLI has a basic UI to show the main insights about the query, the web app provides a richer UI with many more details. An API Key can be found in the Web App, under the page \"API Key\". You can also generate new API Keys on that page.\n\nThe page \"API Keys\" in the web app\n\nIn the CLI, add the API Key using the command setApiKey. For ex. \n\nsetApiKey(\"2pqpXmJ5MKlIofNcUwAe9JECgfmKC9q3R9d5I4q0\") . the Main Commands : In this tutorial you'll use the following commands:\n\naddConnection()\nAdd a new connection to a Postgres server using a prompt\naddApiKey(api-key)\nAdd an API Key. It is required to view the results in the Metis Web App\nconnect(connection-name)\nConnect to the Postgres Server\nqueryAnalysis(sql)\nAnalyze an SQL query . i Run the CLI metis If you haven't downloaded the CLI, please run\n\nbrew tap metis-data/homebrew-cli-brew\nbrew install metis-cli\n\nElse, you can download the binary from here.\n\nRun The CLI\n\nmetis-cli\n\nThe screenshots in this tutorial are of Warp (https://www.warp.dev/) terminal. . to View the Results in the Web App : At the end of the results, the CLI shows a URL. Click on the link to open the web app. Some terminals (such as iTerm2) don't support this functionality. In this case, you'll have to manually copy the URL to the browser.The Analysis of the query in the Web App:\n\nThe Analysis of the query in the Web App:  . to Add a New Connection to Postgres db Add a new connection to a Postgres DB using the command addConnection(). It starts a prompt so you can easily type the properties of the connection string\n\naddConnection()\n\nYou can add a connection string in one line. The connection string can support advanced features the Wizard doesn't support, such as SSL.\naddConnection(\"neondb\",\"postgres\", \"postgres://itay:password@noisy-sun-123456.cloud.neon.tech:5432/main?ssl=true\")\u200b\n\nConnect to the Postgres database.\n\nconnect(\"flights\")\n\nTo view the existing connections use the command listConnections(). \" manage The Workflow . In this tutorial, you'll learn how to analyze an SQL command using Metis CLI. First, you'll configure a connection to the DB. Then you'll run an analysis on the SQL Command. The analysis can be based on the Estimated or the Actual plan.\n\nThe Estimated plan means the SQL command does not run. Instead, the DB engine uses statistics to evaluate what tables and indexes to use and how many rows will be read and returned. The process is very fast but sometimes not as accurate as Actual plan.\nThe Actual plan, as the name suggests, means the DB engine runs the query, which might take a long time. When the SQL command finishes running it provides detailed stats about its execution. \n\nAll of this information is sent to Metis' servers for deep analysis. The CLI returns a direct link to the insights (results) in the web app. . sql Tip - Multi-line SQL string . Sometimes the SQL command is a multi-line one. In this case, the CLI must work in editor mode to continue the command even when a new line starts.\nType .editor \nThen enter the SQL command using the character ` . Notice, do NOT use \" (double quote) or ' (single quote). \n\nMulti-line SQL Command. Don't forget to run CTRL + D to finish ."
  },
  {
    "text": "General  OpenTelemetry\nThe SDK generates a Trace, the REST command caller and every SQL command generated in the code. The technical implementation is a Span (part of a Trace) for the REST command and more Spans for each SQL command, all using the same Trace ID, to allow the backend to show all the spans in the same context.\nGenerating Traces in the code is now a simple task using OpenTelemetry. OpenTelemetry is an open source, vendor agnostic, collection of tools, APIs, and SDKs. It is used to instrument, generate, collect, and export telemetry data (metrics, logs, and traces) to help you analyze your software\u2019s performance and behavior.\nOpenTelemetry provides SDKs for all major Frameworks and ORMs. \n\nAnother cool feature about OpenTelemetry is SQLCommenter. SQLCommenter is a suite of middleware / plugins that enable your ORMs to augment SQL statements before execution, with comments containing information about the code that caused its execution. This helps in easily correlating slow performance with source code and giving insights into backend database performance. In short, it provides some observability into the state of your client-side applications and their impact on the database\u2019s server-side.\n\nSELECT\n    booking.title AS booking_title\nFROM \n    booking\n    /*traceparent='00-59888198e0d98e0d9c1e72d4def4387019030-5fd1362f8aa2affe-1'*/ OpenTelemetry\nThe SDK generates a Trace, the REST command caller and every SQL command generated in the code. The technical implementation is a Span (part of a Trace) for the REST command and more Spans for each SQL command, all using the same Trace ID, to allow the backend to show all the spans in the same context.\nGenerating Traces in the code is now a simple task using OpenTelemetry. OpenTelemetry is an open source, vendor agnostic, collection of tools, APIs, and SDKs. It is used to instrument, generate, collect, and export telemetry data (metrics, logs, and traces) to help you analyze your software\u2019s performance and behavior.\nOpenTelemetry provides SDKs for all major Frameworks and ORMs. \n\nAnother cool feature about OpenTelemetry is SQLCommenter. SQLCommenter is a suite of middleware / plugins that enable your ORMs to augment SQL statements before execution, with comments containing information about the code that caused its execution. This helps in easily correlating slow performance with source code and giving insights into backend database performance. In short, it provides some observability into the state of your client-side applications and their impact on the database\u2019s server-side.\n\nSELECT\n    booking.title AS booking_title\nFROM \n    booking\n    /*traceparent='00-59888198e0d98e0d9c1e72d4def4387019030-5fd1362f8aa2affe-1'*/ Metis SDK sends database related data into our servers. The data includes queries, execution plans, context, and metadata. The data then in turn goes through analysis and insights are derived. historical Overview the Metis SDK sends database related data into our servers. The data includes queries, execution plans, context, and metadata. The data then in turn goes through analysis and insights are derived. \n\nResult\n\nSupported Frameworks and ORM: \n\nPython SQLAlchemy + Flask\nPython SQLAlchemy + FastAPI\nJavaScript Sequelize + Express JS\nJavascript Prisma + Express JS - Coming Soon\nPython Django - Coming Soon\nGo GORM - Coming Soon ! historical Overview the Metis SDK sends traces in to the servers, for deep analysis, which can be viewed in the web app.\n\nSupported Frameworks and ORM: \n\nPython SQLAlchemy + Flask\nPython SQLAlchemy + FastAPI\nJavaScript Sequelize + Express JS\nJavascript Prisma + Express JS - Coming Soon\nPython Django - Coming Soon\nGo GORM - Coming Soon ! Metis SDK sends database related data into our servers. The data includes queries, execution plans, context, and metadata. The data then in turn goes through analysis and insights are derived. other Supported Frameworks  : Python SQLAlchemy + Flask\nPython SQLAlchemy + FastAPI\n\nJavaScript Sequelize + Express\n\nJavascript Prisma + Express\nJavascript Prisma + NestJS . see How it Works .  '"
  },
  {
    "text": "Express  sustainable Development _ METIS_TAG=DEVELOPMENT . st John's Local Enviroment _ METIS_TAG=JOHN_LOCAL . step 3. Check for Success ! Open Up Metis Recent Activity to view your insights! ! step 1. Install . Use the following to install into a project using NPM.\n\nnpm install --save @metis-data/prisma-express-interceptor\n\nOpen your prisma.schema and add to your generator client struct the following line-\n\ngenerator client {\n  ...\n  previewFeatures = [\"tracing\"] // Add this line.\n}\n\nCreate a file named tracing.ts|js, which will contain your Metis setup code. . you Already have OpenTelemetry in your app? !  ! Metis SDK supports Prisma ORM, Node.js and Express.\n\nYou will need your project token for initializing your library. You can get your project token from Projects Page. Metis SDK supports Prisma ORM, Node.js and Express.\n\nYou will need your project token for initializing your library. You can get your project token from Projects Page. Metis SDK supports Prisma ORM, Node.js and Express.\n\nYou will need your project token for initializing your library. You can get your project token from Projects Page. java JavaScript ;  ; type 2. Send Data . Now you can run your application as you normally would, and interact with it in a manner that causes the server to interact with your database. . to Declare Environment , Your Project Token can be used by your organization in different places, by different developers. In order to be able to distinguish the different sources and of data, we require adding an environment variable METIS_TAG. For example:  . someone New to OpenTelemetry? '  . TypeScript\nimport opentelemetry from \"@opentelemetry/api\";\nimport { HttpInstrumentation } from \"@opentelemetry/instrumentation-http\";\nimport { registerInstrumentations } from \"@opentelemetry/instrumentation\";\nimport { Resource } from \"@opentelemetry/resources\";\nimport {\n  BasicTracerProvider, BatchSpanProcessor,\n  ConsoleSpanExporter,\n  SimpleSpanProcessor,\n} from \"@opentelemetry/sdk-trace-base\";\nimport { SemanticResourceAttributes } from \"@opentelemetry/semantic-conventions\";\nimport {\n  getPrismaInstrumentation,\n  createFilter,\n  markSpan, ConfigurationHandler, MetisRemoteExporter,\n} from \"@metis-data/prisma-interceptor\";\nimport { AsyncHooksContextManager } from \"@opentelemetry/context-async-hooks\";\nimport {IncomingMessage} from \"http\";\nconst {\n  serviceName,\n  serviceVersion,\n  exporterUrl,\n  exporterApiKey,\n} = ConfigurationHandler.getMergedConfig({\n  serviceName: \"lior-service\",\n  serviceVersion: \"1.0.0\",\n  exporterUrl: process.env.EXPORTER_URL,\n  exporterApiKey: process.env.EXPORTER_API_KEY,\n});\nconsole.log({\n  serviceName,\n  serviceVersion,\n  exporterUrl,\n  exporterApiKey,\n})\nexport const tracerProvider = new BasicTracerProvider({\n  resource: new Resource({\n    [SemanticResourceAttributes.SERVICE_NAME]: serviceName,\n    [SemanticResourceAttributes.SERVICE_VERSION]: serviceVersion,\n  }),\n});\nexport const metisExporter = new MetisRemoteExporter(\n    exporterUrl,\n    exporterApiKey,\n    {},\n);\ntracerProvider.addSpanProcessor(new BatchSpanProcessor(metisExporter));\ntracerProvider.addSpanProcessor(\n  new SimpleSpanProcessor(new ConsoleSpanExporter()),\n);\nconst contextManager = new AsyncHooksContextManager();\ncontextManager.enable();\nopentelemetry.context.setGlobalContextManager(contextManager);\n// Initialize the OpenTelemetry APIs to use the NodeTracerProvider bindings\ntracerProvider.register();\nexport const metisPrismaInstrumentation = getPrismaInstrumentation();\nconst urlsFilter = createFilter([/favicon.ico/]);\nregisterInstrumentations({\n  instrumentations: [\n    new HttpInstrumentation({\n      ignoreOutgoingRequestHook: () => true,\n      ignoreIncomingRequestHook: (request: IncomingMessage) => {\n        if (request.url) {\n          return urlsFilter(request.url);\n        }\n        return false;\n      },\n      requestHook: markSpan,\n    }),\n    metisPrismaInstrumentation,\n  ],\n}); post Production _ METIS_TAG=PRODUCTION ."
  },
  {
    "text": "What is Metis?  Metis is a database observability tool that enables you to understand the efficiency of your database and the interactions with it. Metis collects database performance data, analyzes it, tells you what's wrong and how to fix it.\n\nOur interface empowers your team to understand your database, no matter their expertise. internet Usage Statistics Tables are Statistics data updated by the database management system (DBMS) on tables size, tables access, index usage, and other elements. . data Schemas define The structure of a database described in a formal language supported by the database management system (DBMS). The schema defines the tables, fields, relationships, views, indexes, packages, procedures, functions, queues, triggers, types, sequences, materialized views, synonyms, database links, directories, XML schemas, and other elements. . additional Instrumentation and Measuring instruments regarded collectively. . the Execution Plans provide A description of the data retrieval methods chosen by the SQL server's query optimizer to perform an SQL Command.\n\nA visualization of an execution plan . an Introduction to Database Observability is \"The ability to measure the internal states of a system by examining its outputs.\"\n\nMetis' instrumentation collects all relevant performance data: Execution Plans, Schemas, SQL Commands, and Usage Statistics Tables.\n\nMetis does not collect sensitive data like the parameters in which sql commands ran with, or the values within the returned rows from a query run. \" - From Observability to Understanding . The collected performance data is constantly inserted into the Metis Insight Engine. The engine uses a rule-based system and series of tests to find issues and come up with the simplest most powerful solutions.\n\nAt Metis, we aim to provide powerful database insights and communicate them in the simplest way. . simple SQL Commands are The instructions used to communicate with a database to perform tasks, functions, and queries with data. . Our interface empowers your team to understand your database, no matter their expertise.\n\nMetis is a database observability tool that enables you to understand the efficiency of your database and the interactions with it. Metis collects database performance data, analyzes it, tells you what's wrong and how to fix it."
  },
  {
    "text": "Projects  Your Project is the work area where you can find your insights, analysis and raw data from your database code, and in the different development cycle phase. - Parameter ; const interceptor = PrismaExpressInterceptor.create({\n  apiKey: string,\n  environment: string,\n  enabled: boolean\n}); ; to Set Up a New Environment , Go to the Project Page (As shown below).\nTap the +Add Environment button.\nChoose it's name.\nPaste the new environment name in METIS_ENVIRONMENT.\n\nProject page . other Environment Variables : METIS_API_KEY=<API_KEY> # e52c013d3748496d9f2f9acb0e6e535b\nMETIS_ENVIRONMENT=<ENVIRONMENT_NAME> # e.g - Metis-Prod\nMETIS_SHOULD_RUN=<BOOLEAN> # TRUE | FALSE | special Projects Page . Create, Delete or Edit projects.\nGet your API Key.\n\nProjects Page . push Pull Requests - Metis can be configured to analyze your Database Code while running tests against real databases during GitHub Pull Requests. Follow this tutorial- . post Production and Production databases are important to companies because they store and manage the data that is critical to the operation of the business. This data may include customer information, financial records, inventory data, and more. Since our SDK sends data about sql queries to our servers, we ask you not to install it in production environment. Instead, Metis offers a Metadata Collector, which collects only metadata and not the actual data.\n\nTo set a Production Metadata Collector follow this tutorial- . natural Environments - When Installing our Metis SDK you are requested to provide three parameters- . a Real Life Example would Say you're a developer who's developing an app. Your app has a frontend and a backend connected to a PostgreSQL database.\n\nYou have a Local Environment (Your personal computer) when you develop your app.\nYou open a Pull Request with the code changes on GitHub, where tests run to test your code.\nYou then (usually) deploy the changes to a Staging Environment where you get to play around with your app with the new changes.\nFinally, after feeling comfortable with the added changes, you deploy the changes to your Production Environment.\n\nProject Page ."
  },
  {
    "text": "ExpressJS - Sequelize  other Environment Variables : METIS_API_KEY\n<String> API Key to use\nMETIS_ENVIRONMENT\n<String> Text used to identify the source that sends the instrumentation data.\nWe suggest you Read This Page to fully understand this feature\nMETIS_DISABLED\n<Boolean> If True Metis Instrumentation is fully disabled. We strongly advise to disable the instrumentation when in production to prevent sensitive data from leaving your organization's database.\nMETIS_SERVICE_NAME\n<String> Gives ability to distinguish between services. Useful when working with Micro Services. . Metis SDK supports Sequelize ORM, Node.js and Express.\n\nYou will need your project token for initializing your library. You can get your project token from Projects Page step 1. Install - Using NPM:\n\nnpm install --save @metis-data/sequelize-express-interceptor\n\nThe interception of Sequelize queries is done by replacing the query function with a function that opens a span, collects the plan, and then executes the actual query. \n\nTo get the plan we must provide the interceptor with a Sequelize instance. That instance would not be instrumented, and should not be used in the application.\n\nYou must create a new Sequelize instance  after instrumentation started. That should be the instance used in the application. . - npm { // package.json\n{\n\"name\": \"my-app\",\n\"main\": \"server.js\", // This is your entry point.\n...\n} ; step 3. Check for Success ! Open Up Metis Recent Activity to view your insights! ! 1. Install\nRun the following command to install the SDK using npm-\n\nnpm install --save @metis-data/sequelize-express-interceptor\n\nOpen your index.ts and add the following code-\n\nconst { SequelizeExpressInterceptor } = require(\u2018@metis-data/sequelize-express-interceptor\u2019)\nconst interceptor = SequelizeExpressInterceptor.create({\n    serviceName: \u2018<SERVICE_NAME>\u2018,\n    serviceVersion: \u2018<SERVICE_VERSION>\u2019,\n    apiKey: \u2018<API_KEY>\u2019\n});\nfunction getSequelizeClient() {\n    const Sequelize = require(\u2018sequelize\u2019)\n    return new Sequelize(\u2018postgres://postgres:password@host:port/postgres\u2019)\n}\ninterceptor.instrument(getSequelizeClient(), {\n    // Add URL Regex to exclude instrumentation from.\n    excludedUrls: [/favicon.ico/],\n});\nconst express = require(\u2018express\u2019);\nconst app = express();\nconst sequelize = getSequelizeClient();\napp.listen(3000, () => {\n    console.log(\u2018Server listening on port 3000\u2019);\n}); . 2. Setup : The interception of Sequelize queries is done by replacing the query function with a function that opens a span, collects the plan, and then executes the actual query. \n\nTo get the plan we must provide the interceptor with a Sequelize instance. That instance would not be instrumented, and should not be used in the application. \n\nYou must create a new Sequelize instance  after instrumentation started. That should be the instance used in the application. . other Environment Variables are METIS_INSTRUMENTATION\nSet false to stop all data collection, any other value activates Metis.\n\nYour Project Token can be used by your organization in different places, by different developers. In order to be able to distinguish the different sources and of data, we require adding an environment variable METIS_TAG. For example:  metis \u00a7 3. Configure . The configuration from the environment will override values passed to the create method.\n\nThe URL of Metis API Gateway. Default: https://ingest.metisdata.io/\nMETIS_EXPORTER_API_KEY\nRequired. A valid API key. Use the page API Key in the web app to see existing ones or create a new one\nSERVICE_NAME\nOptional. A short name of the service to easily group the traces belonging to this service\nSERVICE_VERSION\nOptional. An internal version of the service, to help the developers to distinguish between traces of the latest version and older ones. \nMETIS_EXPORTER_URL . english TypeScript : import { SequelizeExpressInterceptor } from '@metis-data/sequelize-express-interceptor';\nconst interceptor = SequelizeExpressInterceptor.create({\n  apiKey: '<API_KEY>',\n  serviceName: '<SERVICE_NAME>', \n  serviceVersion: '<OPTIONAL_SERVICE_VERSION>',\n});\ninterceptor.instrument(\n  // Do Not use \n  getSequelizeInstance()\n);\nconst sequelize = getSequelizeInstance(); ; sustainable Development _ METIS_TAG=DEVELOPMENT . no Known Issues .  . type 2. Send Data . Now you can run your application as you normally would, and interact with it in a manner that causes the server to interact with your database. . john Docker : # Dockerfile\nFROM node:16\nWORKDIR /usr/src/app\nCOPY package*.json ./\nRUN npm ci\nCOPY . .\nEXPOSE 8080\n// This is your entry point.\nCMD [ \"node\", \"server.js\" ] . java JavaScript : const { SequelizeExpressInterceptor } = require('@metis-data/sequelize-express-interceptor');\nconst interceptor = SequelizeExpressInterceptor.create({\n  apiKey: '<API_KEY>',\n  serviceName: '<SERVICE_NAME>', \n  serviceVersion: '<OPTIONAL_SERVICE_VERSION>',\n});\nconst sequelizeForPlan = getSequelizeInstance()\ninterceptor.instrument(\n  sequelizeForPlan\n);\nconst sequelize = getSequelizeInstance() ; st John's Local Enviroment _ METIS_TAG=JOHN_LOCAL . type 2. Send Data . Now you can run your application as you normally would, and interact with it in a manner that causes the server to interact with your database. . step 3. Check for Success ! Open Up Metis Recent Activity to view your insights!\n\nES Modules\nCurrently this package can only be used in CommonJS modules, and it will not work with ES modules. The issue stems from the fact that we need to provide a Sequelize instance to the instrumentation. That means we need to import Sequelize, and that causes issues with the patching of Sequelize. To solve this issue we clear the required cache internally when instrument is called.\nTypescript can be used, but it needs to target CommonJS. . the CommonJS and ES Modules. but Currently this package can only be used in CommonJS modules, and it will not work with ES modules. The issue stems from the fact that we need to provide a Sequelize instance to the instrumentation. That means we need to import Sequelize, and that causes issues with the patching of Sequelize. To solve this issue we clear the required cache internally when instrument is called.\n\nTypescript can be used, but it needs to target CommonJS. . post Production _ METIS_TAG=PRODUCTION ."
  },
  {
    "text": "Environments  then Dive into the REST API Commands .  . Each Project can set up Environments. An Environment is a running app with our SDK installed.\n\nCurrently we support only a Single Environment per Project.\nMultiple Environments support is coming soon!\n\nProject's page, with the Environments column is marked. living Inside an Environment and Clicking on an environment, moves you to the recent activity page where you can see the latest REST API Commands send from the SDK only consist SQL Commands.\n\nStaging Environment Page ."
  },
  {
    "text": "Simple  step 3. Check for Success ! Open Up Metis Recent Activity to view your insights! ! 1. Install\nRun the following command to install the SDK using npm-\n\nnpm install --save @metis-data/prisma-interceptor\n\nOpen your prisma.schema and add to your generator client struct the following line-\n\ngenerator client {\n  ...\n  previewFeatures = [\"tracing\"] // Add this line.\n}\n\nRun the following command-\n\nprisma generate\n\nIf you followed the NestJS docs to implement Prisma, you already created a prisma.service.ts. Open it and add the following code-\n\nimport { setInstrumentedPrismaClient } from \"@metis-data/prisma-interceptor\";\nimport { Injectable, OnModuleInit } from \"@nestjs/common\";\nimport { PrismaClient } from \"@prisma/client\";\n@Injectable()\nexport class PrismaService extends PrismaClient implements OnModuleInit {\n    constructor() {\n        super({\n            log: [{\n                emit: \"event\",\n                level: \"query\",\n            }]\n        });\n    }\n    async onModuleInit() {\n        await this.$connect();\n        setInstrumentedPrismaClient(this)\n    }\n}\n\nOpen your main.ts and add the following code-\n\nimport { AppModule } from './app.module';\nimport { NestFactory } from '@nestjs/core';\nimport { PrismaNestInterceptor } from '@metis-data/prisma-nest-interceptor';\nconst interceptor = PrismaNestInterceptor.create({\n  serviceName: '<SERVICE_NAME>',\n  serviceVersion: '<SERVICE_VERSION>',\n  apiKey: '<API_KEY>'\n});\n// Add URL Regex to exclude instrumentation from.\ninterceptor.instrument({ excludedUrls: [/favicon.ico/] });\nasync function bootstrap() {\n  const app = await NestFactory.create(AppModule);\n  await app.listen(3000);\n}\nbootstrap(); other Environment Variables : METIS_API_KEY\n<String> API Key to use\nMETIS_ENVIRONMENT\n<String> Text used to identify the source that sends the instrumentation data.\nWe suggest you Read This Page to fully understand this feature\nMETIS_DISABLED\n<Boolean> If True Metis Instrumentation is fully disabled. We strongly advise to disable the instrumentation when in production to prevent sensitive data from leaving your organization's database.\nMETIS_SERVICE_NAME\n<String> Gives ability to distinguish between services. Useful when working with Micro Services. . type 2. Send Data . Now you can run your application as you normally would, and interact with it in a manner that causes the server to interact with your database. ."
  },
  {
    "text": "Database Connections  & REPL . addConnection() - the wizard asks for the necessary properties. \n\nAdding a new connection using a Wizard . . Connect .  . historical Overview : When analyzing queries via the queryAnalysis() command, by default our engines analyze the query regardless of the database it'll run against. You can however provide a connection to the database that you would like to test your query against.\n\nWe highly recommend adding a connection when analyzing queries, as we provide stronger insights against the scenario the queries will actually be tested in. . & REPL . connect('connection-name') ; - CLI - metis-cli list-connections . - CLI - No need to connect in CLI mode. Your default connection will be used.\n\nYou can set the default connection by running-\n\n\nmetis-cli set-default-connection 'connection-name' . to View existing Connections .  . & REPL . addConnection() . - CLI - metis-cli add-connection ; to Create a New Connection , Open the CLI tool and type the following command- . & REPL . listConnections() ."
  }
]